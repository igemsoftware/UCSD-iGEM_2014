{
 "metadata": {
  "name": "",
  "signature": "sha256:2ec897febfa9c62dc42c682644df4ab5fc7bec348cddf6fffc572dc16cffdc41"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''finds the last index of an element in a sequence'''\n",
      "def rindex(sequence, element):\n",
      "    for i, e in enumerate(reversed(sequence)):\n",
      "        if element == e:\n",
      "            return len(sequence) - 1 - i\n",
      "    else:\n",
      "            raise ValueError(\"rindex(sequence, element): element not in the sequence\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''removes the outer most parentheses \"()\" and returns the token afte the \")\"'''\n",
      "def parentheses(sequence):\n",
      "    print \"parentheses(sequence): sequence: \", sequence\n",
      "    first_opener_idx_assigned = False\n",
      "    started = False\n",
      "    counter = 0\n",
      "    for idx, e in enumerate(sequence):\n",
      "        if e == '(':\n",
      "            if started == False:\n",
      "                started = True\n",
      "            counter = counter + 1\n",
      "        elif e == ')':\n",
      "            if started == False:\n",
      "                raise ValueError(\"parentheses(sequence): ')' without '('\")\n",
      "            counter = counter - 1\n",
      "        if started == True:\n",
      "            if first_opener_idx_assigned == False:\n",
      "                first_opener_idx = idx\n",
      "                first_opener_idx_assigned = True\n",
      "            if counter == 0:\n",
      "                sequence.pop(idx)\n",
      "                if idx < len(sequence):\n",
      "                    element_after_last_closer = sequence[idx]\n",
      "                else:\n",
      "                    element_after_last_closer = None\n",
      "                sequence.pop(first_opener_idx)\n",
      "                return element_after_last_closer\n",
      "    print \"parentheses(sequence): no parentehses in the sequence\"\n",
      "    return None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''splits a sequence by a given element and stores the elements\n",
      "before and after the element into a dictionary'''\n",
      "def split_by(sequence, element):\n",
      "    element_index = sequence.index(element)\n",
      "    sequence_before_element = sequence[:element_index:1]\n",
      "    sequence_after_element = sequence[element_index + 1::1]\n",
      "    return {0: sequence_before_element, 1: sequence_after_element}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''class: UISA (User Input Syntax Analyzer)'''\n",
      "class UISA:\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''constructor'''\n",
      "    def __init__(self, tokens):\n",
      "        print \"UISA.__init__(self, tokens): tokens: \", tokens\n",
      "        \"beigns syntax-analyzer-semantic-evaluator recursion\"\n",
      "        print \"RETURN:\\n\", self.g0(tokens)\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''g0:= g1 > g1'''\n",
      "    def g0(self, tokens):\n",
      "        print \"UISA.g(self, tokens): tokens: \", tokens\n",
      "        if '>' not in tokens:\n",
      "            raise ValueError(\"g(self, tokens): no output\")\n",
      "        else:\n",
      "            input_output_dictionary = split_by(tokens, '>')\n",
      "        return self.gOutput(self.g1(input_output_dictionary[0]), self.g1(input_output_dictionary[1]))\n",
      "        \n",
      "    \n",
      "    \n",
      "    '''g1:= g2 or g1 | g2 and g1 | g2'''\n",
      "    def g1(self, tokens):        \n",
      "        print \"UISA.g1(self, tokens): tokens: \", tokens\n",
      "        if len(tokens) > 1 and tokens[1] == 'or':\n",
      "            \"g2 or g1\"\n",
      "            print \"UISA.g0(self, tokens): detected 'or'\"\n",
      "            \"splits tokens by the first occuring 'or' and stores the tokens before and after the 'or' in a dictionary\"\n",
      "            or_dictionary = split_by(tokens, 'or')\n",
      "            return self.gOr(self.g2(or_dictionary.get(0)), self.g1(or_dictionary.get(1)))\n",
      "        elif len(tokens) > 1 and tokens[1] == 'and':\n",
      "            \"g2 and g1\"\n",
      "            print \"UISA.g1(self, tokens): detected 'and'\"\n",
      "            \"splits tokens by the first occuring 'and' and stores the tokens before and after the 'and' in a dictionary\"\n",
      "            and_dictionary = split_by(tokens, 'and')\n",
      "            return self.gAnd(self.g2(and_dictionary.get(0)), self.g1(and_dictionary.get(1)))            \n",
      "        else:\n",
      "            \"g2\"\n",
      "            \"delegates to g2\"\n",
      "            return self.g2(tokens)\n",
      "        \n",
      "        \n",
      "        \n",
      "    '''g2:= (g1) or g1 | (g1) and g1 | (g1) | interactor''' \n",
      "    def g2(self, tokens):\n",
      "        print \"UISA.g2(self, tokens): tokens: \", tokens\n",
      "        if tokens[0] == \"(\":\n",
      "            \"(g1) or g1 | (g1) and g1| (g1)\"\n",
      "            print \"UISA.g2(self, tokens): detected '('\"\n",
      "            \"token after the last occuring ')'\"\n",
      "            token_after_last_closer = parentheses(tokens)\n",
      "            if token_after_last_closer == 'or':    \n",
      "                \"splits tokens by the first occuring 'or' and stores the tokens before and after the 'or' in a dictionary\"\n",
      "                or_dictionary = split_by(tokens, 'or')\n",
      "                return self.gOr(self.g1(or_dictionary.get(0)), self.g1(or_dictionary.get(1)))\n",
      "            elif token_after_last_closer == 'and':\n",
      "                \"splits tokens by the first occuring 'and' and stores the tokens before and after the 'and' in a dictionary\"\n",
      "                and_dictionary = split_by(tokens, 'and')\n",
      "                return self.gAnd(self.g1(and_dictionary.get(0)), self.g1(and_dictionary.get(1)))\n",
      "            else:\n",
      "                \"delegates to interactor\"\n",
      "                return self.g1(tokens)\n",
      "        else:\n",
      "            \"interactor\"\n",
      "            \"delegates to interactor\"\n",
      "            return self.interactor(tokens)\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''interactor:= lacI | cI | ... | etc.'''\n",
      "    def interactor(self, tokens):\n",
      "        print \"UISA.interactor(self, tokens): tokens: \", tokens\n",
      "        \"returns an interactor\"\n",
      "        return tokens\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''>'''\n",
      "    def gOutput(self, tokens1, tokens2):\n",
      "        toBeReturned = []\n",
      "        for token1 in tokens1:\n",
      "            for token2 in tokens2:\n",
      "                toBeReturned.append(('[' + token1 + '] ---> [' + token2 + ']'))\n",
      "        return toBeReturned\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''Or'''\n",
      "    def gOr(self, tokens1, tokens2):\n",
      "        return tokens1 + tokens2\n",
      "    \n",
      "    \n",
      "    \n",
      "    '''And'''\n",
      "    def gAnd(self, tokens1, tokens2):\n",
      "        toBeReturned = []\n",
      "        for token1 in tokens1:\n",
      "            for token2 in tokens2:\n",
      "                toBeReturned.append(token1 + (\" and \" + token2))\n",
      "        return toBeReturned"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''main'''\n",
      "def main(user_input):\n",
      "    user_input_token= user_input.split()\n",
      "    uisa = UISA(user_input_token)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "main(\"( A and B and C ) or D or E > X\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "UISA.__init__(self, tokens): tokens:  ['(', 'A', 'and', 'B', 'and', 'C', ')', 'or', 'D', 'or', 'E', '>', 'X']\n",
        "RETURN:\n",
        "UISA.g(self, tokens): tokens:  ['(', 'A', 'and', 'B', 'and', 'C', ')', 'or', 'D', 'or', 'E', '>', 'X']\n",
        "UISA.g1(self, tokens): tokens:  ['(', 'A', 'and', 'B', 'and', 'C', ')', 'or', 'D', 'or', 'E']\n",
        "UISA.g2(self, tokens): tokens:  ['(', 'A', 'and', 'B', 'and', 'C', ')', 'or', 'D', 'or', 'E']\n",
        "UISA.g2(self, tokens): detected '('\n",
        "parentheses(sequence): sequence:  ['(', 'A', 'and', 'B', 'and', 'C', ')', 'or', 'D', 'or', 'E']\n",
        "UISA.g1(self, tokens): tokens:  ['A', 'and', 'B', 'and', 'C']\n",
        "UISA.g1(self, tokens): detected 'and'\n",
        "UISA.g2(self, tokens): tokens:  ['A']\n",
        "UISA.interactor(self, tokens): tokens:  ['A']\n",
        "UISA.g1(self, tokens): tokens:  ['B', 'and', 'C']\n",
        "UISA.g1(self, tokens): detected 'and'\n",
        "UISA.g2(self, tokens): tokens:  ['B']\n",
        "UISA.interactor(self, tokens): tokens:  ['B']\n",
        "UISA.g1(self, tokens): tokens:  ['C']\n",
        "UISA.g2(self, tokens): tokens:  ['C']\n",
        "UISA.interactor(self, tokens): tokens:  ['C']\n",
        "UISA.g1(self, tokens): tokens:  ['D', 'or', 'E']\n",
        "UISA.g0(self, tokens): detected 'or'\n",
        "UISA.g2(self, tokens): tokens:  ['D']\n",
        "UISA.interactor(self, tokens): tokens:  ['D']\n",
        "UISA.g1(self, tokens): tokens:  ['E']\n",
        "UISA.g2(self, tokens): tokens:  ['E']\n",
        "UISA.interactor(self, tokens): tokens:  ['E']\n",
        "UISA.g1(self, tokens): tokens:  ['X']\n",
        "UISA.g2(self, tokens): tokens:  ['X']\n",
        "UISA.interactor(self, tokens): tokens:  ['X']\n",
        "['[A and B and C] ---> [X]', '[D] ---> [X]', '[E] ---> [X]']\n"
       ]
      }
     ],
     "prompt_number": 19
    }
   ],
   "metadata": {}
  }
 ]
}